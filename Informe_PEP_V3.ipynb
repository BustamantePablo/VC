{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f945c6c-ceab-4afc-a255-e788eee1d32f",
   "metadata": {},
   "source": [
    "#### LIBRERIAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77461d95-d9a0-4ca6-968c-746bffbcd0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import re\n",
    "import unicodedata\n",
    "import math\n",
    "from itertools import cycle\n",
    "import xlsxwriter\n",
    "import pyodbc\n",
    "\n",
    "import random\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41620f2b-f95b-46c1-adb8-04723825467d",
   "metadata": {},
   "source": [
    "Posteriormente, en el informe PEP se deben añadir las operaciones sospechosas relacionadas a individuos PEP.\n",
    "Los Sujetos Obligados deben registrar cualquier operación en que esté involucrada alguna persona que deba ser calificada como PEP, así como informarla por vía electrónica a esta Unidad a la brevedad posible, cuando se considera que se está en presencia de una operación sospechosa.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18519a1e-4483-40d5-8b3a-6b37ba04f2f7",
   "metadata": {},
   "source": [
    "#### FUNCIONES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54a90da2-6970-46f9-b17e-05cffcec5e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcula_dv(rut_base):\n",
    "    # Convertir el RUT base a una cadena y revertirla\n",
    "    reversed_digits = list(map(int, str(rut_base)[::-1]))\n",
    "    # Definir los factores (2..7) que se repiten en ciclo\n",
    "    factors = list(range(2, 8))\n",
    "    # Calcular la suma de los productos\n",
    "    suma = sum(d * f for d, f in zip(reversed_digits, factors * (len(reversed_digits) // len(factors) + 1)))\n",
    "    # Calcular el dígito verificador\n",
    "    dv = (-suma) % 11\n",
    "    return 'K' if dv == 10 else str(dv)\n",
    "\n",
    "def remove_leading_zeros(rut):\n",
    "    rut_part, dv = rut.split('-')\n",
    "    rut_part = rut_part.lstrip('0')\n",
    "    if not rut_part:\n",
    "        rut_part = '0'\n",
    "    return f\"{rut_part}-{dv}\"\n",
    "\n",
    "def reemplazar_k(identificador):\n",
    "    return identificador[:-1:] + identificador[-1].upper()\n",
    "\n",
    "def separar_rut(numero):\n",
    "    numero_str = str(numero)\n",
    "    # Tomar los últimos 1 dígito y el resto\n",
    "    parte_numerica = numero_str[:-1]\n",
    "    digito_verificador = numero_str[-1]\n",
    "    # Formatear el RUT con el guion\n",
    "    rut_formateado = f\"{parte_numerica}-{digito_verificador}\"\n",
    "    return rut_formateado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ee5b7f-d7f7-4365-bea3-14d5c50065ba",
   "metadata": {},
   "source": [
    "### SE DEBE MODIFICAR LOS SIGUIENTES DATOS DE INPUT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e65c3b5-d7e8-4b81-aa22-2e737a9c382c",
   "metadata": {},
   "source": [
    "<table>\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th>QRY_NAME</th>\n",
    "      <th>FECHA</th>\n",
    "      <th>DF_NAME</th>\n",
    "      <th>DESCRIPCIÓN</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td>query_operacion_final</td>\n",
    "      <td>[]</td>\n",
    "      <td>df_info_personal_test</td>\n",
    "      <td>Última operación del cliente</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>query_info_personal</td>\n",
    "      <td>[]</td>\n",
    "      <td>df_info_personal</td>\n",
    "      <td>Info personal del cliente</td>\n",
    "    </tr>\n",
    "      <tr>\n",
    "      <td>query_ultima_operacion</td>\n",
    "      <td>[YYYY0-MM0-DD0] ; [YYYY-MM-DD]</td>\n",
    "      <td> df_ultima_operacion</td>\n",
    "      <tdOperaciones dentro del periodoe</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>query_CustodiaClientes</td>\n",
    "      <td>[YYYY-MM-DD]</td>\n",
    "      <td>df_cartera_detalle</td>\n",
    "      <td>Cartera Vigente Detallada</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>query_SaldoCaja</td>\n",
    "      <td>[YYYY-MM-DD]</td>\n",
    "      <td>df_saldo_caja</td>\n",
    "      <td>Datos Caja</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>query_APORET</td>\n",
    "      <td>[YYYY0-MM0-DD0] ; [YYYY-MM-DD]</td>\n",
    "      <td>df_APORET_detalle</td>\n",
    "      <td>Aportes Retiros Detalle</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>query_IndicadorCustodia</td>\n",
    "      <td>[YYYY-MM-DD]</td>\n",
    "      <td>df_indicador</td>\n",
    "      <td>Indicador custodia</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86c25e9c-62ce-4e8d-a451-5026567f3842",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 'YYYY-MM-DD'\n",
    "F_i = '2024-10-14'  # Fecha inicial\n",
    "F = '2024-10-18'  # Fecha \n",
    "F_cartera_caja = '2024-10-17' # dia previo si es viernes\n",
    "## CONSULTA DEL SALDO DE CAJA Y CUSTODIA TIENE QUE SER RESPECTO FECHA CIERRE ANTERIOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f822e62-5488-4559-a038-76495d2c7d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "FICHA_PEP = 'FICHA PEP/Ficha PEP 18-10-2024'\n",
    "NIVEL_PEP = 'Relacionados_PEP'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0ae981-8883-4ee5-8219-d37e942f23f3",
   "metadata": {},
   "source": [
    "#### CLIENTES PEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19d29a9b-5f25-4da0-ae14-36df284bbb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ficha_pep = pd.read_excel(f\"{FICHA_PEP}.xlsx\")\n",
    "df_nivel_pep = pd.read_excel(f\"{NIVEL_PEP}.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4d48956-4b25-40a9-a1ab-3394d0dfb346",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ficha_pep = df_ficha_pep[['NOMBRE','APELLIDO PATERNO', 'APELLIDO MATERNO', 'Dni']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51d1b071-40f8-44db-a278-bc302dc339eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ficha_pep.loc[:, 'Nombre Cliente'] = df_ficha_pep['NOMBRE'].astype(str) +\" \"+df_ficha_pep['APELLIDO PATERNO'].astype(str) +\" \"+df_ficha_pep['APELLIDO MATERNO'].astype(str)\n",
    "df_ficha_pep['Dni'] = df_ficha_pep['Dni'].apply(separar_rut)\n",
    "del df_ficha_pep['NOMBRE']\n",
    "del df_ficha_pep['APELLIDO PATERNO']\n",
    "del df_ficha_pep['APELLIDO MATERNO']\n",
    "df_ficha_pep = df_ficha_pep.rename(columns={'Dni': 'IDENTIFICADOR', 'Nombre Cliente': 'NOMBRE CLIENTE'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25565393-ff13-47d3-83e5-42c2dcb5a177",
   "metadata": {},
   "source": [
    "#### INFORMACION PEP ADICIONAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8921d902-fa14-433f-8f32-829a9bf5411a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nivel_pep['IDENTIFICADOR'] = df_nivel_pep['IDENTIFICADOR'].apply(separar_rut)\n",
    "df_nivel_pep['RUT PEP RELACIONADO'] = df_nivel_pep['RUT PEP RELACIONADO'].apply(separar_rut)\n",
    "df_nivel_pep['RUT PEP RELACIONADO'] = df_nivel_pep['RUT PEP RELACIONADO'].apply(reemplazar_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbe3825-20eb-49f6-8ef5-22bccdda9aa5",
   "metadata": {},
   "source": [
    "#### IDENTIFICADORES PEP DE LA FICHA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2101deb7-d4ed-4869-bebb-7f19f13a3550",
   "metadata": {},
   "outputs": [],
   "source": [
    "identificadores_PEP = df_ficha_pep['IDENTIFICADOR'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2374c6da-df02-4e5a-9a56-5405d9e1ede3",
   "metadata": {},
   "outputs": [],
   "source": [
    "identificadores = df_ficha_pep['IDENTIFICADOR'].tolist()\n",
    "# SEPARAR POR COMAS\n",
    "identificadores_str = ','.join([f\"'{id}'\" for id in identificadores])\n",
    "### OBTIENE ULTIMA OPERACION DEL CLIENTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e400c76b-a729-4e65-9583-67e371ecd6a6",
   "metadata": {},
   "source": [
    "#### CONSULTAS PARTE 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91ebb205-46f2-4921-b649-a6174050a93a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Francisco Betancour\\AppData\\Local\\Temp\\ipykernel_18144\\2762942999.py:32: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_info_personal_test = pd.read_sql(query_universal['query_operacion_final'], conn)\n"
     ]
    }
   ],
   "source": [
    "query_universal = {\n",
    "\n",
    "    'query_operacion_final': f\"\"\"\n",
    "WITH OperacionesOrdenadas AS (\n",
    "    SELECT \n",
    "        [NUM_CUENTA],\n",
    "        [IDENTIFICADOR],\n",
    "        [NOMBRE_CLIENTE],\n",
    "        [NOMBRE_ASESOR],\n",
    "        [FECHA_OPERACION],\n",
    "        [COD_TIPO_OPERACION],\n",
    "        [DSC_OPERACION_CONCEPTO],\n",
    "        [COD_MONEDA_OP],\n",
    "        [NEMOTECNICO],\n",
    "        [DSC_INSTRUMENTO],\n",
    "        [COD_SUB_CLASE_INSTRUMENTO],\n",
    "        [CANTIDAD],\n",
    "        [MONTO],\n",
    "        [MONTO_OPERACION],\n",
    "        ROW_NUMBER() OVER (PARTITION BY [IDENTIFICADOR] ORDER BY [FECHA_OPERACION] DESC) AS rn\n",
    "    FROM [Capitaria].[dbo].[OPERACION_CLIENTE_JGG]\n",
    "    WHERE [IDENTIFICADOR] IN ({identificadores_str})\n",
    ")\n",
    "SELECT *\n",
    "FROM OperacionesOrdenadas\n",
    "WHERE rn = 1;\"\"\"\n",
    "}\n",
    "\n",
    "# CONN TO DB\n",
    "conn = pyodbc.connect('DRIVER={SQL Server};SERVER=tcp:mi-sql-prd-002.5bf1e89c8cf2.database.windows.net;DATABASE=capitaria;UID=pablobustamante;PWD=S3cur3!PassPB5sta#2024')\n",
    "# EXECUTE\n",
    "df_info_personal_test = pd.read_sql(query_universal['query_operacion_final'], conn)\n",
    "\n",
    "# CLOSE\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaad2bf6-43cb-429b-880b-1e00c2b0c560",
   "metadata": {},
   "source": [
    "#### CONSULTAS PARTE 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d4c6f6a-1cc5-425d-9bdb-77d7ff3abcd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Francisco Betancour\\AppData\\Local\\Temp\\ipykernel_18144\\386275727.py:56: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_info_personal = pd.read_sql(query_universal['query_info_personal'], conn)\n",
      "C:\\Users\\Francisco Betancour\\AppData\\Local\\Temp\\ipykernel_18144\\386275727.py:57: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_ultima_operacion = pd.read_sql(query_universal['query_ultima_operacion'], conn)\n"
     ]
    }
   ],
   "source": [
    "identificadores = df_ficha_pep['IDENTIFICADOR'].tolist()\n",
    "# SEPARAR POR COMAS\n",
    "identificadores_str = ','.join([f\"'{id}'\" for id in identificadores])\n",
    "\n",
    "query_universal = {\n",
    "\n",
    "    'query_info_personal': f\"\"\"\n",
    "        SELECT [NUM_CUENTA]\n",
    "              ,[DSC_CUENTA]\n",
    "              ,[ESTADO_CUENTA]\n",
    "              ,[COD_MONEDA]\n",
    "              ,[FECHA_OPERATIVA]\n",
    "              ,[NOMBRE_CLIENTE]\n",
    "              ,[NOMBRE_ASESOR]\n",
    "              ,[FLG_MOV_DESCUBIERTOS]\n",
    "              ,[DSC_PERFIL_RIESGO]\n",
    "              ,[NOMBRE_CLIENTE_P]\n",
    "              ,[FECHA_NACIMIENTO]\n",
    "              ,[IDENTIFICADOR]\n",
    "              ,[COD_PAIS]\n",
    "              ,[PROFESION]\n",
    "              ,[EMPLEADOR]\n",
    "              ,[CARGO]\n",
    "          FROM [Capitaria].[dbo].[CLIENTES_JG]\n",
    "\n",
    "        WHERE \n",
    "        [IDENTIFICADOR] IN ({identificadores_str}); \n",
    "    \"\"\",\n",
    "\n",
    "    'query_ultima_operacion': f\"\"\"\n",
    "\n",
    "            SELECT \n",
    "                [NUM_CUENTA],\n",
    "                [IDENTIFICADOR],\n",
    "                [NOMBRE_CLIENTE],\n",
    "                [NOMBRE_ASESOR],\n",
    "                [FECHA_OPERACION],\n",
    "                [COD_TIPO_OPERACION],\n",
    "                [DSC_OPERACION_CONCEPTO],\n",
    "                [COD_MONEDA_OP],\n",
    "                [NEMOTECNICO],\n",
    "                [DSC_INSTRUMENTO],\n",
    "                [COD_SUB_CLASE_INSTRUMENTO],\n",
    "                [CANTIDAD],\n",
    "                [MONTO],\n",
    "                [MONTO_OPERACION]\n",
    "            FROM [Capitaria].[dbo].[OPERACION_CLIENTE_JGG]\n",
    "            WHERE [IDENTIFICADOR] IN ({identificadores_str})\n",
    "            AND FECHA_OPERACION BETWEEN CONVERT(datetime, '{F_i}', 120) AND CONVERT(datetime, '{F}', 120)\n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    "# CONN TO DB\n",
    "conn = pyodbc.connect('DRIVER={SQL Server};SERVER=tcp:mi-sql-prd-002.5bf1e89c8cf2.database.windows.net;DATABASE=capitaria;UID=pablobustamante;PWD=S3cur3!PassPB5sta#2024')\n",
    "# EXECUTE\n",
    "df_info_personal = pd.read_sql(query_universal['query_info_personal'], conn)\n",
    "df_ultima_operacion = pd.read_sql(query_universal['query_ultima_operacion'], conn)\n",
    "# CLOSE\n",
    "conn.close()\n",
    "\n",
    "## qry ultima operacion toma todas las operaciones del periodo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e691a25-f3ae-41b6-aef3-9a382d8fb85a",
   "metadata": {},
   "source": [
    "#### CONSULTAS PARTE 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b321862a-87bb-4794-ac4f-79acf91613e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Francisco Betancour\\AppData\\Local\\Temp\\ipykernel_18144\\2317256833.py:47: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_cartera_detalle = pd.read_sql(query_universal['query_CustodiaClientes'], conn)\n"
     ]
    }
   ],
   "source": [
    "query_universal = {\n",
    "    'query_CustodiaClientes': f\"\"\"\n",
    "        SELECT\n",
    "            C.PRECIO_TASA_MERCADO,\n",
    "            C.PRECIO_TASA_COMPRA,\n",
    "            V.NUM_CUENTA,\n",
    "            V.ID_CUENTA,\n",
    "            V.DSC_CUENTA AS NOMBRE_CLI,\n",
    "            C.CANTIDAD AS LIBRE,\n",
    "            C.GARANTIA,\n",
    "            C.COMPRAS_PLAZO,\n",
    "            C.VENTAS_PLAZO,\n",
    "            CASE \n",
    "                WHEN PRESTAMOS IS NULL THEN 0 \n",
    "                ELSE PRESTAMOS \n",
    "            END AS PRESTAMOS_ACC,\n",
    "            V.IDENTIFICADOR,\n",
    "            I.NEMOTECNICO,\n",
    "            V.NOMBRE_ASESOR,\n",
    "            CASE \n",
    "                WHEN COD_SUB_CLASE_INSTRUMENTO IN ('CFI', 'ACC') AND I.COD_MONEDA = 'CLP' THEN CANTIDAD * PRECIO_TASA_MERCADO \n",
    "                WHEN COD_SUB_CLASE_INSTRUMENTO IN ('CFI', 'ACC') AND I.COD_MONEDA <> 'CLP' THEN (VALOR_MERCADO_CLP / (CANTIDAD + GARANTIA) * CANTIDAD)\n",
    "                ELSE (VALOR_MERCADO_CLP / (CANTIDAD + GARANTIA) * CANTIDAD) \n",
    "            END AS LIBRE_CLP,\n",
    "            CASE \n",
    "                WHEN COD_SUB_CLASE_INSTRUMENTO IN ('CFI', 'ACC') AND I.COD_MONEDA = 'CLP' THEN GARANTIA * PRECIO_TASA_MERCADO \n",
    "                WHEN COD_SUB_CLASE_INSTRUMENTO IN ('CFI', 'ACC') AND I.COD_MONEDA <> 'CLP' THEN (VALOR_MERCADO_CLP / (CANTIDAD + GARANTIA) * GARANTIA)\n",
    "                ELSE (VALOR_MERCADO_CLP / (CANTIDAD + GARANTIA) * GARANTIA) \n",
    "            END AS GARANTIA_CLP,\n",
    "            C.COMPRAS_PLAZO * C.PRECIO_TASA_MERCADO AS SIM_COMPRA_CLP,\n",
    "            C.VENTAS_PLAZO * C.PRECIO_TASA_MERCADO AS SIM_VENTA_CLP,\n",
    "            C.VALOR_MERCADO_CLP,\n",
    "            I.COD_SUB_CLASE_INSTRUMENTO\n",
    "        FROM\n",
    "            dbo.cierre_cartera_resumida AS C WITH (NOLOCK)\n",
    "            INNER JOIN dbo.VIEW_CUENTAS AS V WITH (NOLOCK) ON C.ID_CUENTA = V.ID_CUENTA\n",
    "            INNER JOIN dbo.INSTRUMENTO AS I WITH (NOLOCK) ON C.ID_INSTRUMENTO = I.ID_INSTRUMENTO\n",
    "        WHERE\n",
    "            C.FECHA_CIERRE = CONVERT(datetime, '{F_cartera_caja}', 120) \n",
    "            AND V.IDENTIFICADOR IN ({identificadores_str});\n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    "# CONN TO DB\n",
    "conn = pyodbc.connect('DRIVER={SQL Server};SERVER=tcp:mi-sql-prd-002.5bf1e89c8cf2.database.windows.net;DATABASE=capitaria;UID=pablobustamante;PWD=S3cur3!PassPB5sta#2024')\n",
    "# EXECUTE\n",
    "df_cartera_detalle = pd.read_sql(query_universal['query_CustodiaClientes'], conn)\n",
    "# CLOSE\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0b36e0-c303-4de1-bb7b-eb484d8c67a1",
   "metadata": {},
   "source": [
    "#### CONSULTAS PARTE 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12135e98-977a-46b2-8fa3-f396475e724d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Francisco Betancour\\AppData\\Local\\Temp\\ipykernel_18144\\3363267685.py:20: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_indicador = pd.read_sql(query_universal['query_IndicadorCustodia'], conn)\n"
     ]
    }
   ],
   "source": [
    "query_universal = {\n",
    "    \n",
    "    'query_IndicadorCustodia': f\"\"\"\n",
    "        SELECT\n",
    "            SUM(C.VALOR_MERCADO_CLP) AS SUM_VALOR_MERCADO_CLP\n",
    "        FROM\n",
    "            dbo.cierre_cartera_resumida AS C WITH (NOLOCK)\n",
    "            INNER JOIN dbo.VIEW_CUENTAS AS V WITH (NOLOCK) ON C.ID_CUENTA = V.ID_CUENTA\n",
    "            INNER JOIN dbo.INSTRUMENTO AS I WITH (NOLOCK) ON C.ID_INSTRUMENTO = I.ID_INSTRUMENTO\n",
    "        WHERE\n",
    "            C.FECHA_CIERRE = CONVERT(datetime, '{F_cartera_caja}', 120) \n",
    "            AND I.COD_SUB_CLASE_INSTRUMENTO <> 'ACC_INT'\n",
    "    \"\"\"\n",
    "\n",
    "}\n",
    "\n",
    "# CONN TO DB\n",
    "conn = pyodbc.connect('DRIVER={SQL Server};SERVER=tcp:mi-sql-prd-002.5bf1e89c8cf2.database.windows.net;DATABASE=capitaria;UID=pablobustamante;PWD=S3cur3!PassPB5sta#2024')\n",
    "# EXECUTE\n",
    "df_indicador = pd.read_sql(query_universal['query_IndicadorCustodia'], conn)\n",
    "# CLOSE\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2a603c-e8ab-43f0-8d5e-1d7839e4dabb",
   "metadata": {},
   "source": [
    "#### CONSULTAS PARTE 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e39fc57-4257-4cc5-ac34-316259f7cbef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Francisco Betancour\\AppData\\Local\\Temp\\ipykernel_18144\\2274696490.py:85: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_saldo_caja = pd.read_sql(query_universal['query_SaldoCaja'], conn)\n",
      "C:\\Users\\Francisco Betancour\\AppData\\Local\\Temp\\ipykernel_18144\\2274696490.py:86: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_APORET_detalle = pd.read_sql(query_universal['query_APORET'], conn)\n"
     ]
    }
   ],
   "source": [
    "query_universal = {\n",
    "\n",
    "    'query_SaldoCaja': f\"\"\"\n",
    "\n",
    "    SELECT DISTINCT \n",
    "        A.NOMBRE_ASESOR, \n",
    "        A.IDENTIFICADOR,\n",
    "        b.NUM_CUENTA, \n",
    "        b.DSC_CUENTA AS NOMBRE_CLI, \n",
    "        b.TIPO_CAJA, \n",
    "        b.MONTO_MON_CAJA, \n",
    "        b.MONTO_EN_PESOS, \n",
    "        b.TRANSITO\n",
    "        FROM \n",
    "        dbo.VIEW_CUENTAS AS A\n",
    "        INNER JOIN (\n",
    "        SELECT DISTINCT \n",
    "            C.ID_CUENTA, \n",
    "            C.NUM_CUENTA, \n",
    "            C.DSC_CUENTA, \n",
    "            A.FECHA_CIERRE, \n",
    "            A.EST_SALDO_CAJA AS ESTADO, \n",
    "            CASE \n",
    "                WHEN DSC_CAJA_CUENTA = 'CAJA PESOS' THEN 'CAJA PESO' \n",
    "                ELSE DSC_CAJA_CUENTA \n",
    "            END AS TIPO_CAJA, \n",
    "            A.MONTO_MON_CAJA, \n",
    "            A.MONTO_MON_CUENTA AS MONTO_EN_PESOS, \n",
    "            A.MONTO_X_PAGAR_MON_CTA, \n",
    "            A.MONTO_X_COBRAR_MON_CTA, \n",
    "            A.MONTO_X_COBRAR_MON_CTA - A.MONTO_X_PAGAR_MON_CTA AS TRANSITO\n",
    "        FROM \n",
    "            dbo.CUENTA AS C WITH (NOLOCK)\n",
    "        INNER JOIN \n",
    "            dbo.CAJA_CUENTA AS B WITH (NOLOCK) ON C.ID_CUENTA = B.ID_CUENTA\n",
    "        INNER JOIN \n",
    "            dbo.SALDO_CAJA AS A WITH (NOLOCK) ON B.ID_CAJA_CUENTA = A.ID_CAJA_CUENTA\n",
    "        WHERE \n",
    "            a.FECHA_CIERRE = CONVERT(datetime, '{F_cartera_caja}', 120) \n",
    "            AND A.EST_SALDO_CAJA = 'VIG' \n",
    "            AND (A.MONTO_X_PAGAR_MON_CTA + A.MONTO_X_COBRAR_MON_CTA + A.MONTO_MON_CUENTA) <> 0\n",
    "        ) AS b ON A.NUM_CUENTA = b.NUM_CUENTA\n",
    "        WHERE \n",
    "        A.IDENTIFICADOR IN ({identificadores_str}); \n",
    "    \"\"\",\n",
    "\n",
    "\n",
    "        'query_APORET': f\"\"\"\n",
    "        SELECT \n",
    "        CARGO_ABONO,\n",
    "        NUM_CUENTA,\t\n",
    "        IDENTIFICADOR,\t\n",
    "        NOMBRE_CLI,\t\n",
    "        COD_MOV,\t\n",
    "        DSC_MOV_CAJA,\t\n",
    "        FECHA_MOVIMIENTO,\t\n",
    "        MONTO,\n",
    "        NOMBRE_ASESOR,\t\n",
    "        TIPO_CAJA,\t\n",
    "        COD_MONEDA,\t\t\n",
    "        T_C,\t\n",
    "        MONTO_CLP\n",
    "\n",
    "        FROM [Capitaria].[dbo].[MOV_CAJA_CLI_JGG]\n",
    "        WHERE COD_MOV IN (\n",
    "            'APO_PAT',\n",
    "            'APO_PAT_AT',\n",
    "            'APO_PAT_BT',\n",
    "            'APO_PAT_LI',\n",
    "            'APO_PAT_RC',\n",
    "            'RET_PAT',\n",
    "            'RET_PAT_BA',\n",
    "            'RET_PAT_BT',\n",
    "            'RET_PAT_EX',\n",
    "            'RET_PAT_LI'\n",
    "            )\n",
    "        AND FECHA_MOVIMIENTO BETWEEN CONVERT(datetime, '{F_i}', 120) AND CONVERT(datetime, '{F}', 120)\n",
    "        AND IDENTIFICADOR IN ({identificadores_str});\n",
    "        \"\"\"\n",
    "}\n",
    "\n",
    "# CONN TO DB\n",
    "conn = pyodbc.connect('DRIVER={SQL Server};SERVER=tcp:mi-sql-prd-002.5bf1e89c8cf2.database.windows.net;DATABASE=capitaria;UID=pablobustamante;PWD=S3cur3!PassPB5sta#2024')\n",
    "# EXECUTE\n",
    "df_saldo_caja = pd.read_sql(query_universal['query_SaldoCaja'], conn)\n",
    "df_APORET_detalle = pd.read_sql(query_universal['query_APORET'], conn)\n",
    "# CLOSE\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "09e1b5a5-5efa-447a-b28d-495c7119976c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NUM_CUENTA</th>\n",
       "      <th>DSC_CUENTA</th>\n",
       "      <th>ESTADO_CUENTA</th>\n",
       "      <th>COD_MONEDA</th>\n",
       "      <th>FECHA_OPERATIVA</th>\n",
       "      <th>NOMBRE_CLIENTE</th>\n",
       "      <th>NOMBRE_ASESOR</th>\n",
       "      <th>FLG_MOV_DESCUBIERTOS</th>\n",
       "      <th>DSC_PERFIL_RIESGO</th>\n",
       "      <th>NOMBRE_CLIENTE_P</th>\n",
       "      <th>FECHA_NACIMIENTO</th>\n",
       "      <th>IDENTIFICADOR</th>\n",
       "      <th>COD_PAIS</th>\n",
       "      <th>PROFESION</th>\n",
       "      <th>EMPLEADOR</th>\n",
       "      <th>CARGO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>10159793/60</td>\n",
       "      <td>VICTOR ANTONIO CONCHA LABRA</td>\n",
       "      <td>HABILITADO</td>\n",
       "      <td>CLP</td>\n",
       "      <td>2024-09-27</td>\n",
       "      <td>Victor Antonio Concha Labra</td>\n",
       "      <td>RACIONAL .</td>\n",
       "      <td>S</td>\n",
       "      <td>CONSERVADOR</td>\n",
       "      <td>Victor Antonio</td>\n",
       "      <td>1965-06-05</td>\n",
       "      <td>10159793-8</td>\n",
       "      <td>CL</td>\n",
       "      <td>Contador</td>\n",
       "      <td>Servicios Integrales</td>\n",
       "      <td>Técnico</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      NUM_CUENTA                   DSC_CUENTA ESTADO_CUENTA COD_MONEDA  \\\n",
       "236  10159793/60  VICTOR ANTONIO CONCHA LABRA    HABILITADO        CLP   \n",
       "\n",
       "    FECHA_OPERATIVA               NOMBRE_CLIENTE NOMBRE_ASESOR  \\\n",
       "236      2024-09-27  Victor Antonio Concha Labra    RACIONAL .   \n",
       "\n",
       "    FLG_MOV_DESCUBIERTOS DSC_PERFIL_RIESGO NOMBRE_CLIENTE_P FECHA_NACIMIENTO  \\\n",
       "236                    S       CONSERVADOR   Victor Antonio       1965-06-05   \n",
       "\n",
       "    IDENTIFICADOR COD_PAIS PROFESION              EMPLEADOR    CARGO  \n",
       "236    10159793-8       CL  Contador  Servicios Integrales   Técnico  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236    VICTOR ANTONIO CONCHA LABRA\n",
      "Name: NOMBRE_CLIENTE, dtype: object\n"
     ]
    }
   ],
   "source": [
    "id = '10159793-8'\n",
    "display(df_info_personal[df_info_personal['IDENTIFICADOR'] == id])\n",
    "s = df_info_personal[df_info_personal['IDENTIFICADOR'] == id]['NOMBRE_CLIENTE']\n",
    "s_upper = s.str.upper()  # Use .str.upper() to apply upper() to each element in the Series\n",
    "print(s_upper)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124ddeb3-e9d7-483f-b99f-c55235f8718d",
   "metadata": {},
   "source": [
    "#### DF DESCARGADOS DE CONSULTAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ed8cad64-4ec4-4ad6-bd85-4c964308bffd",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'rn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3791\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3790\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3791\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3792\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'rn'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m### BORRAR COLUMNAS DE INFO PERSONAL(CONTIENE ULTIMA OPERACION)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m df_info_personal_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrn\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:4441\u001b[0m, in \u001b[0;36mNDFrame.__delitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4436\u001b[0m             deleted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   4437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m deleted:\n\u001b[0;32m   4438\u001b[0m     \u001b[38;5;66;03m# If the above loop ran and didn't delete anything because\u001b[39;00m\n\u001b[0;32m   4439\u001b[0m     \u001b[38;5;66;03m# there was no match, this call should raise the appropriate\u001b[39;00m\n\u001b[0;32m   4440\u001b[0m     \u001b[38;5;66;03m# exception:\u001b[39;00m\n\u001b[1;32m-> 4441\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4442\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39midelete(loc)\n\u001b[0;32m   4444\u001b[0m \u001b[38;5;66;03m# delete from the caches\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3798\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3793\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3794\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3795\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3796\u001b[0m     ):\n\u001b[0;32m   3797\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3798\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3799\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3800\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3803\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'rn'"
     ]
    }
   ],
   "source": [
    "### BORRAR COLUMNAS DE INFO PERSONAL(CONTIENE ULTIMA OPERACION)\n",
    "del df_info_personal_test['rn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6e4f87-aa6f-47de-92c2-84f3002605bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "425ab1e7-2271-4147-b8d4-696dd8944045",
   "metadata": {},
   "source": [
    "#### CARTERA DETALLE Y RESUMIDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9c9e8d97-88cc-4671-a5ab-558c7d5b497e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'MONTO_CLP'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18144\\996933448.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_APORET_detalle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_APORET_detalle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'MONTO_CLP'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mascending\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[0;32m   6940\u001b[0m             )\n\u001b[0;32m   6941\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6942\u001b[0m             \u001b[1;31m# len(by) == 1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6943\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6944\u001b[1;33m             \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6945\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6946\u001b[0m             \u001b[1;31m# need to rewrap column in Series to apply key function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6947\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1840\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mother_axes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1841\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_level_reference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1843\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1844\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1845\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1846\u001b[0m         \u001b[1;31m# Check for duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1847\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'MONTO_CLP'"
     ]
    }
   ],
   "source": [
    "df_APORET_detalle = df_APORET_detalle.sort_values(by='MONTO_CLP', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3119a848-9284-4846-9aa6-bfa7a94cf06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DETALLE CARTERA\n",
    "columns_q1 = ['NUM_CUENTA', 'NOMBRE_CLI', 'IDENTIFICADOR', 'NOMBRE_ASESOR','NEMOTECNICO','COD_SUB_CLASE_INSTRUMENTO',\n",
    "              'VALOR_MERCADO_CLP','LIBRE', 'GARANTIA', 'PRECIO_TASA_COMPRA', 'PRECIO_TASA_MERCADO','COMPRAS_PLAZO','VENTAS_PLAZO',\n",
    "              'PRESTAMOS_ACC','LIBRE_CLP','GARANTIA_CLP','SIM_COMPRA_CLP','SIM_VENTA_CLP']\n",
    "\n",
    "df_cartera_detalle = df_cartera_detalle[columns_q1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04d74393-e19c-4088-8c2b-ea056a7c6667",
   "metadata": {},
   "outputs": [],
   "source": [
    "### RESUMIDA \n",
    "df_cartera_RESUMIDA = df_cartera_detalle.pivot_table(\n",
    "    index=['IDENTIFICADOR', 'NOMBRE_CLI', 'NOMBRE_ASESOR'],\n",
    "    columns='COD_SUB_CLASE_INSTRUMENTO',\n",
    "    values='VALOR_MERCADO_CLP',\n",
    "    aggfunc='sum'\n",
    ").fillna(0).reset_index()\n",
    "\n",
    "df_cartera_RESUMIDA.columns.name = None  # ELIMINAR NOMBRE DE COLUMNAS\n",
    "df_cartera_RESUMIDA['TOTAL CUSTODIA CLP'] = df_cartera_RESUMIDA[[col for col in df_cartera_RESUMIDA.columns if col not in ['IDENTIFICADOR', 'NOMBRE_CLI', 'NOMBRE_ASESOR']]].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0f6582b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SUMAR INDEPENDIENTE DEL ASESOR\n",
    "cols_no_sumar = ['IDENTIFICADOR', 'NOMBRE_CLI', 'NOMBRE_ASESOR']\n",
    "cols_a_sumar = [col for col in df_cartera_RESUMIDA.columns if col not in cols_no_sumar]\n",
    "suma_por_identificador = df_cartera_RESUMIDA.groupby('IDENTIFICADOR')[cols_a_sumar].sum()\n",
    "\n",
    "df_cartera_RESUMIDA = suma_por_identificador.reset_index()\n",
    "df_cartera_RESUMIDA = df_cartera_RESUMIDA.sort_values(by='TOTAL CUSTODIA CLP', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6106d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PARA PONER ASESORES ENROLAMIENTO\n",
    "df_info_personal_ASE = df_info_personal.groupby('IDENTIFICADOR')['NOMBRE_ASESOR'].unique().reset_index()\n",
    "df_info_personal_ASE.columns = ['IDENTIFICADOR', 'ASESORES_CUSTODIA']\n",
    "\n",
    "df_info_personal_ASE = df_info_personal.groupby('IDENTIFICADOR').agg({\n",
    "    'NOMBRE_ASESOR': lambda x: list(x.unique()),\n",
    "    'PROFESION': 'first',\n",
    "    'EMPLEADOR': 'first',\n",
    "    'CARGO': 'first',\n",
    "    'FECHA_OPERATIVA': 'first',\n",
    "    'DSC_PERFIL_RIESGO': 'first',\n",
    "    'FECHA_NACIMIENTO': 'first',\n",
    "    'COD_PAIS': 'first',\n",
    "}).fillna(' ').reset_index()\n",
    "\n",
    "df_info_personal_ASE['IDENTIFICADOR'] = df_info_personal_ASE['IDENTIFICADOR'].apply(reemplazar_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50630242-7499-4717-b15e-a7d65f4f5422",
   "metadata": {},
   "source": [
    "#### SALDO CAJA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dec25094-95d9-4e46-bc53-38a6a89921dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "neworder =  ['NUM_CUENTA','NOMBRE_CLI','IDENTIFICADOR','NOMBRE_ASESOR',\n",
    "    'TIPO_CAJA', 'MONTO_MON_CAJA', 'MONTO_EN_PESOS', 'TRANSITO']\n",
    "df_saldo_caja=df_saldo_caja.reindex(columns=neworder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e5b5d0f-4b50-46b2-84a9-cbe9187892e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_saldo_caja_RESUMIDA = df_saldo_caja.pivot_table(\n",
    "    index=['IDENTIFICADOR', 'NOMBRE_CLI', 'NOMBRE_ASESOR'],\n",
    "    columns='TIPO_CAJA',\n",
    "    values='MONTO_EN_PESOS',\n",
    "    aggfunc='sum'\n",
    ").fillna(0).reset_index()\n",
    "\n",
    "df_saldo_caja_RESUMIDA.columns.name = None\n",
    "df_saldo_caja_RESUMIDA['TOTAL CAJA CLP'] = df_saldo_caja_RESUMIDA[\n",
    "    [col for col in df_saldo_caja_RESUMIDA.columns if col not in ['IDENTIFICADOR', 'NOMBRE_CLI', 'NOMBRE_ASESOR']]\n",
    "].sum(axis=1)\n",
    "\n",
    "## SUMAR INDEPENDIENTE DEL ASESOR\n",
    "cols_no_sumar = ['IDENTIFICADOR', 'NOMBRE_CLI', 'NOMBRE_ASESOR']\n",
    "cols_a_sumar = [col for col in df_saldo_caja_RESUMIDA.columns if col not in cols_no_sumar]\n",
    "suma_por_identificador = df_saldo_caja_RESUMIDA.groupby('IDENTIFICADOR')[cols_a_sumar].sum()\n",
    "\n",
    "df_saldo_caja_RESUMIDA = suma_por_identificador.reset_index()\n",
    "df_saldo_caja_RESUMIDA = df_saldo_caja_RESUMIDA.sort_values(by='TOTAL CAJA CLP', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5aa673-2d72-40f6-93c4-46dc1ebcac83",
   "metadata": {},
   "source": [
    "#### APORTES RETIROS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "29fbe1f4-eac4-49ad-8269-7a7802f76ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#del df_APORET_detalle['Unnamed: 0'] esta no estaba\n",
    "df_APORET_RESUMEN = df_APORET_detalle.groupby(['IDENTIFICADOR','CARGO_ABONO', 'TIPO_CAJA'], as_index=False)['MONTO_CLP'].sum().fillna(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfb4626-ea20-4633-962c-79b14f56e3e9",
   "metadata": {},
   "source": [
    "#### RESUMEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0413fc1e-04bf-4ca3-9c55-de49bb98d416",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cartera_RESUMIDA['IDENTIFICADOR'] = df_cartera_RESUMIDA['IDENTIFICADOR'].apply(reemplazar_k)\n",
    "df_saldo_caja_RESUMIDA['IDENTIFICADOR'] = df_saldo_caja_RESUMIDA['IDENTIFICADOR'].apply(reemplazar_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e6ac8104-475e-4199-acff-b385b0b69088",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resumen = df_nivel_pep.copy()\n",
    "df_cartera_RESUMIDA_2 = df_cartera_RESUMIDA.copy()\n",
    "df_saldo_caja_RESUMIDA_2 = df_saldo_caja_RESUMIDA.copy()\n",
    "\n",
    "\n",
    "df_resumen = pd.merge(df_resumen, df_cartera_RESUMIDA_2, on=['IDENTIFICADOR'], how='outer')\n",
    "df_resumen = pd.merge(df_resumen, df_saldo_caja_RESUMIDA_2 , on=['IDENTIFICADOR'], how='outer')\n",
    "\n",
    "df_resumen = df_resumen.sort_values(by='TOTAL CUSTODIA CLP', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8ca7f1a3-67d6-48c1-8f50-07f2fa7aad58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NUM_CUENTA</th>\n",
       "      <th>DSC_CUENTA</th>\n",
       "      <th>ESTADO_CUENTA</th>\n",
       "      <th>COD_MONEDA</th>\n",
       "      <th>FECHA_OPERATIVA</th>\n",
       "      <th>NOMBRE_CLIENTE</th>\n",
       "      <th>NOMBRE_ASESOR</th>\n",
       "      <th>FLG_MOV_DESCUBIERTOS</th>\n",
       "      <th>DSC_PERFIL_RIESGO</th>\n",
       "      <th>NOMBRE_CLIENTE_P</th>\n",
       "      <th>FECHA_NACIMIENTO</th>\n",
       "      <th>IDENTIFICADOR</th>\n",
       "      <th>COD_PAIS</th>\n",
       "      <th>PROFESION</th>\n",
       "      <th>EMPLEADOR</th>\n",
       "      <th>CARGO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>7972965/50</td>\n",
       "      <td>MAY  CHOMALI GARIB</td>\n",
       "      <td>HABILITADO</td>\n",
       "      <td>CLP</td>\n",
       "      <td>2024-10-14</td>\n",
       "      <td>MAY  CHOMALI GARIB</td>\n",
       "      <td>BETTERPLAN ADVISORS SPA  .</td>\n",
       "      <td>S</td>\n",
       "      <td>ARRIESGADO</td>\n",
       "      <td>MAY</td>\n",
       "      <td>1958-06-18</td>\n",
       "      <td>7972965-5</td>\n",
       "      <td>CL</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     NUM_CUENTA          DSC_CUENTA ESTADO_CUENTA COD_MONEDA FECHA_OPERATIVA  \\\n",
       "238  7972965/50  MAY  CHOMALI GARIB    HABILITADO        CLP      2024-10-14   \n",
       "\n",
       "         NOMBRE_CLIENTE               NOMBRE_ASESOR FLG_MOV_DESCUBIERTOS  \\\n",
       "238  MAY  CHOMALI GARIB  BETTERPLAN ADVISORS SPA  .                    S   \n",
       "\n",
       "    DSC_PERFIL_RIESGO NOMBRE_CLIENTE_P FECHA_NACIMIENTO IDENTIFICADOR  \\\n",
       "238        ARRIESGADO             MAY        1958-06-18     7972965-5   \n",
       "\n",
       "    COD_PAIS PROFESION EMPLEADOR CARGO  \n",
       "238       CL      None      None  None  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_info_personal[df_info_personal['IDENTIFICADOR'] == '7972965-5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "436943a3-37d8-4136-9385-969f5d7325cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_df_aporet = df_APORET_RESUMEN.pivot_table(\n",
    "    index=['IDENTIFICADOR'],\n",
    "    columns=['CARGO_ABONO', 'TIPO_CAJA'],\n",
    "    values='MONTO_CLP',\n",
    "    aggfunc='sum',\n",
    ").fillna(' ')\n",
    "\n",
    "# RESETEAR INDICE\n",
    "pivot_df_aporet = pivot_df_aporet.reset_index()\n",
    "pivot_df_aporet['IDENTIFICADOR'] = pivot_df_aporet['IDENTIFICADOR'].apply(reemplazar_k)\n",
    "# AJUSTAR DATA FRAME\n",
    "pivot_df_aporet.columns = [\n",
    "    'IDENTIFICADOR', \n",
    "    'ABONO_CAJA_DOLAR', 'ABONO_CAJA_PESO', \n",
    "    'CARGO_CAJA_DOLAR', 'CARGO_CAJA_PESO']\n",
    "pivot_df_aporet = pivot_df_aporet.fillna(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "14913fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_df_aporet_2 = pivot_df_aporet.copy()\n",
    "df_resumen = pd.merge(df_resumen, pivot_df_aporet_2, on=['IDENTIFICADOR'], how='outer')\n",
    "df_resumen = pd.merge(df_resumen, df_info_personal_ASE, on=['IDENTIFICADOR'], how='outer')\n",
    "\n",
    "### AGREGAR ULTIMA OPERACION\n",
    "df_ultima_operacion['IDENTIFICADOR'] = df_ultima_operacion['IDENTIFICADOR'].apply(reemplazar_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "33d8084a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ultima_operacion_UNIQUE = df_ultima_operacion.groupby('IDENTIFICADOR').agg({\n",
    "    'COD_SUB_CLASE_INSTRUMENTO': lambda x: list(x.unique())\n",
    "    }).fillna(' ').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "20ef5c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resumen = pd.merge(df_resumen, df_ultima_operacion_UNIQUE, on=['IDENTIFICADOR'], how='outer')\n",
    "df_resumen = df_resumen.fillna(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "40af811a-985d-44a4-8bef-a0900ff47b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CANTIDAD DE OPERACIONES\n",
    "df_cant_operaciones = df_ultima_operacion['IDENTIFICADOR'].value_counts().reset_index(name='CANTIDAD_OPERACIONES')\n",
    "\n",
    "df_resumen = pd.merge(df_resumen, df_cant_operaciones, on=['IDENTIFICADOR'], how='outer')\n",
    "df_resumen = df_resumen.fillna(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d88a2fe7-2576-4c63-8d14-ae32de10b8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resumen['TOTAL CUSTODIA CLP'] = pd.to_numeric(df_resumen['TOTAL CUSTODIA CLP'], errors='coerce')\n",
    "df_resumen['ACC_INT'] = pd.to_numeric(df_resumen['ACC_INT'], errors='coerce')\n",
    "\n",
    "custodia_total = df_indicador['SUM_VALOR_MERCADO_CLP'].values[0]  \n",
    "custodia_pep_suma = df_resumen['TOTAL CUSTODIA CLP'].sum()-df_resumen['ACC_INT'].sum()\n",
    "\n",
    "# INDICE COMO PORCENTAJE\n",
    "indice = (custodia_pep_suma / custodia_total) * 100  # Obtén el índice como número\n",
    "indice_formateado = f\"{indice:.4f}%\"  # Formatea el índice con 4 decimales y agrega el símbolo %\n",
    "\n",
    "# ESTRUCTURA DF INDICADOR\n",
    "data = {\n",
    "    'CUSTODIA': ['PEP', 'TOTAL', 'INDICADOR'],\n",
    "    'MONTO': [custodia_pep_suma, custodia_total, indice_formateado]\n",
    "}\n",
    "\n",
    "df_indicador_numero = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "23502ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "### RENOMBRAR COLUMNAS\n",
    "df_resumen = df_resumen.rename(columns={'INFO NAME': 'NOMBRE CLIENTE', \n",
    "                                        'NOMBRE_ASESOR': 'ASESORES',\n",
    "                                        'DSC_PERFIL_RIESGO': 'PERFIL_RIESGO',\n",
    "                                        'COD_SUB_CLASE_INSTRUMENTO': 'PRODUCTOS_OPERADOS',\n",
    "                                        'COD_PAIS': 'PAIS'\n",
    "                                       })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "41a5251d-9aa3-480b-b324-692080a8a30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### AÑADE INFO DE ULTIMA OPERACION\n",
    "df_info_personal_test_2 = df_info_personal_test.copy()\n",
    "df_info_personal_test_2 = df_info_personal_test_2[['IDENTIFICADOR','FECHA_OPERACION','COD_SUB_CLASE_INSTRUMENTO']]\n",
    "\n",
    "df_info_personal_test_2['IDENTIFICADOR'] = df_info_personal_test_2['IDENTIFICADOR'].apply(reemplazar_k)\n",
    "\n",
    "df_resumen = pd.merge(df_resumen, df_info_personal_test_2, on=['IDENTIFICADOR'], how='outer')\n",
    "df_resumen = df_resumen.fillna(' ')\n",
    "\n",
    "df_resumen =df_resumen.rename(columns={\"COD_SUB_CLASE_INSTRUMENTO\": \"ULTIMO_INSTRUMENTO_OPERADO\", \"FECHA_OPERACION\": \"FECHA_ULTIMA_OPERACION\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9be261-d75f-43d2-8ee7-bd3da020cbbe",
   "metadata": {},
   "source": [
    "#### INDICADORES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c99ddcc2-f0f3-4059-a4be-e287e242527f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOTALES FORMATO NUM\n",
    "df_resumen['TOTAL CAJA CLP'] = pd.to_numeric(df_resumen['TOTAL CAJA CLP'], errors='coerce')\n",
    "df_resumen['TOTAL CUSTODIA CLP'] = pd.to_numeric(df_resumen['TOTAL CUSTODIA CLP'], errors='coerce')\n",
    "# OBTENCION TOP 10\n",
    "top10_caja = df_resumen.groupby(['IDENTIFICADOR', 'NOMBRE CLIENTE'])['TOTAL CAJA CLP'].sum().nlargest(10).reset_index()\n",
    "top10_custodia = df_resumen.groupby(['IDENTIFICADOR', 'NOMBRE CLIENTE'])['TOTAL CUSTODIA CLP'].sum().nlargest(10).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "be589d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONVERTIR COLUMNAS A NUM\n",
    "columns_to_convert = ['ACC', 'ACC_INT', 'CFI', 'ETF', 'FMF']\n",
    "for col in columns_to_convert:\n",
    "    df_resumen[col] = pd.to_numeric(df_resumen[col], errors='coerce')\n",
    "\n",
    "# TOP 10 DE CADA PRODUCTO\n",
    "top10_products = {}\n",
    "for col in columns_to_convert:\n",
    "    top10_products[col] = df_resumen.groupby(['IDENTIFICADOR', 'NOMBRE CLIENTE'])[col].sum().nlargest(10).reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4273b2c5",
   "metadata": {},
   "source": [
    "#### CUSTODIA TOP 10 PEP RESPECTO TOTAL PEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "42fc29d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "custodia_pep_suma = df_resumen['TOTAL CUSTODIA CLP'].sum()\n",
    "top10_custodia_suma = top10_custodia['TOTAL CUSTODIA CLP'].sum()\n",
    "\n",
    "# Calcular el índice como porcentaje\n",
    "indice_2 = (top10_custodia_suma / custodia_pep_suma) * 100  # Obtén el índice como número\n",
    "indice_formateado_2 = f\"{indice_2:.4f}%\"  # Formatea el índice con 4 decimales y agrega el símbolo %\n",
    "\n",
    "# Crear el DataFrame con la estructura solicitada\n",
    "data_2 = {\n",
    "    'CUSTODIA': ['TOP 10 PEP', 'TOTAL PEP', 'INDICADOR'],\n",
    "    'MONTO': [top10_custodia_suma, custodia_pep_suma, indice_formateado_2]\n",
    "}\n",
    "\n",
    "df_indicador_numero2 = pd.DataFrame(data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f45ac353",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resumen = df_resumen.rename(columns={'INFO NAME': 'NOMBRE CLIENTE', \n",
    "                                        'NOMBRE_ASESOR': 'ASESORES',\n",
    "                                        'DSC_PERFIL_RIESGO': 'PERFIL_RIESGO',\n",
    "                                        'COD_SUB_CLASE_INSTRUMENTO': 'PRODUCTOS_OPERADOS',\n",
    "                                        'COD_PAIS': 'PAIS',\n",
    "                                       })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9916184b",
   "metadata": {},
   "source": [
    "## GENERAR EXCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "320a8f2f-3b7d-4cd0-a585-0235e09a188d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def format_and_save_excel_with_alternating_colors(filename, logo_path, dfs_with_format=None, dfs_without_format=None, dfs_multiple_on_sheet=None):\n",
    "    if dfs_with_format is None:\n",
    "        dfs_with_format = {}\n",
    "    if dfs_without_format is None:\n",
    "        dfs_without_format = {}\n",
    "    if dfs_multiple_on_sheet is None:\n",
    "        dfs_multiple_on_sheet = {}\n",
    "\n",
    "    todays_date = date.today().strftime('%Y-%d-%m')\n",
    "\n",
    "    with pd.ExcelWriter(filename, engine='xlsxwriter') as writer:\n",
    "        # FORMATEO COLORES ALTERNOS\n",
    "        def format_sheet_with_alternating_colors(df, sheet_name):\n",
    "            df.to_excel(writer, sheet_name=sheet_name, index=False, startrow=4, header=False)  # Start from row 4\n",
    "\n",
    "            workbook = writer.book\n",
    "            worksheet = writer.sheets[sheet_name]\n",
    "\n",
    "            # Insert the logo at B1 (row 1, column 2)\n",
    "            worksheet.insert_image('A1', logo_path)\n",
    "\n",
    "            # Insert today's date in D1\n",
    "            worksheet.write('C2', todays_date, workbook.add_format({'bold': True, 'font_size': 12}))\n",
    "\n",
    "            # FORMATO HEADER\n",
    "            header_format = workbook.add_format({\n",
    "                'bold': True,\n",
    "                'text_wrap': True,\n",
    "                'valign': 'top',\n",
    "                'fg_color': '#022596',\n",
    "                'font_color': 'white',\n",
    "                'border': 1\n",
    "            })\n",
    "\n",
    "            worksheet.set_default_row(15)\n",
    "            for col_idx in range(len(df.columns)):\n",
    "                worksheet.set_column(col_idx, col_idx, 20)\n",
    "\n",
    "            worksheet.add_table(3, 0, len(df) + 3, len(df.columns) - 1, {  # Adjust to row 4 (3-based index)\n",
    "                'columns': [{'header': col} for col in df.columns],\n",
    "                'style': 'none'\n",
    "            })\n",
    "\n",
    "            # Write the headers manually\n",
    "            for col_num, value in enumerate(df.columns.values):\n",
    "                worksheet.write(3, col_num, value, header_format)  # Header row at row 4 (3-based index)\n",
    "\n",
    "            # Alternate row colors\n",
    "            format1 = workbook.add_format({'bg_color': '#FFFFFF', 'align': 'left'})\n",
    "            format2 = workbook.add_format({'bg_color': '#E0FFFF', 'align': 'left'})\n",
    "            date_format1 = workbook.add_format({'bg_color': '#FFFFFF', 'align': 'left', 'num_format': 'yyyy-mm-dd'})\n",
    "            date_format2 = workbook.add_format({'bg_color': '#E0FFFF', 'align': 'left', 'num_format': 'yyyy-mm-dd'})\n",
    "\n",
    "            previous_identifier = None\n",
    "            format_to_use = format1\n",
    "            date_format_to_use = date_format1\n",
    "\n",
    "            for row_num, identifier in enumerate(df['IDENTIFICADOR'], start=4):  # Start at row 4\n",
    "                if identifier != previous_identifier:\n",
    "                    format_to_use = format2 if format_to_use == format1 else format1\n",
    "                    date_format_to_use = date_format2 if date_format_to_use == date_format1 else date_format1\n",
    "                    previous_identifier = identifier\n",
    "\n",
    "                for col_num in range(len(df.columns)):\n",
    "                    value = df.iloc[row_num - 4, col_num]  # Adjust for the new row index\n",
    "\n",
    "                    if pd.isna(value) or (isinstance(value, float) and (value == float('inf') or value == -float('inf'))):\n",
    "                        value = ''  # Replace NaN or Infinity with an empty string\n",
    "                    elif isinstance(value, (list, np.ndarray)):\n",
    "                        value = ', '.join(map(str, value))  # Convert lists or arrays to a string\n",
    "\n",
    "                    if df.columns[col_num].startswith('FECHA'):\n",
    "                        worksheet.write(row_num, col_num, value, date_format_to_use)\n",
    "                    else:\n",
    "                        worksheet.write(row_num, col_num, value, format_to_use)\n",
    "\n",
    "        # FORMATEO HOJA SIN COLORES ALTERNOS\n",
    "        def format_sheet_without_alternating_colors(df, sheet_name, start_row=3, insert_logo=True):\n",
    "            df.to_excel(writer, sheet_name=sheet_name, index=False, startrow=start_row, header=False)\n",
    "\n",
    "            workbook = writer.book\n",
    "            worksheet = writer.sheets[sheet_name]\n",
    "\n",
    "            # Only insert the logo and date if insert_logo is True\n",
    "            if insert_logo:\n",
    "                worksheet.insert_image('A1', logo_path)\n",
    "                worksheet.write('C2', todays_date, workbook.add_format({'bold': True, 'font_size': 12}))\n",
    "\n",
    "            header_format = workbook.add_format({\n",
    "                'bold': True,\n",
    "                'text_wrap': True,\n",
    "                'valign': 'top',\n",
    "                'fg_color': '#022596',\n",
    "                'font_color': 'white',\n",
    "                'border': 1\n",
    "            })\n",
    "\n",
    "            worksheet.set_default_row(15)\n",
    "            for col_idx in range(len(df.columns)):\n",
    "                worksheet.set_column(col_idx, col_idx, 20)\n",
    "\n",
    "            worksheet.add_table(start_row, 0, start_row + len(df), len(df.columns) - 1, {\n",
    "                'columns': [{'header': col} for col in df.columns],\n",
    "                'style': 'none'\n",
    "            })\n",
    "\n",
    "            # Write the headers manually\n",
    "            for col_num, value in enumerate(df.columns.values):\n",
    "                worksheet.write(start_row, col_num, value, header_format)\n",
    "\n",
    "            cell_format = workbook.add_format({'align': 'left', 'bg_color': '#FFFFFF'})\n",
    "            date_format = workbook.add_format({'num_format': 'yyyy-mm-dd', 'bg_color': '#FFFFFF'})\n",
    "\n",
    "            for row_num in range(start_row + 1, start_row + len(df) + 1):\n",
    "                for col_num in range(len(df.columns)):\n",
    "                    value = df.iloc[row_num - start_row - 1, col_num]\n",
    "\n",
    "                    if isinstance(value, (list, np.ndarray)):\n",
    "                        value = ', '.join(map(str, value))  # Convert lists or arrays to a string\n",
    "                    elif pd.isna(value) or (isinstance(value, float) and (value == float('inf') or value == -float('inf'))):\n",
    "                        value = ''  # Replace NaN or Infinity with an empty string\n",
    "\n",
    "                    if df.columns[col_num].startswith('FECHA'):\n",
    "                        worksheet.write(row_num, col_num, value, date_format)\n",
    "                    else:\n",
    "                        worksheet.write(row_num, col_num, value, cell_format)\n",
    "\n",
    "        # VARIOS DF EN UNA SHEET\n",
    "        def format_multiple_dfs_on_sheet(dfs, sheet_name):\n",
    "            workbook = writer.book\n",
    "            worksheet = workbook.add_worksheet(sheet_name)\n",
    "            writer.sheets[sheet_name] = worksheet\n",
    "\n",
    "            # Insert the logo at B1 (row 1, column 2) - only once\n",
    "            worksheet.insert_image('A1', logo_path)\n",
    "\n",
    "            # Insert today's date in C1 - only once\n",
    "            worksheet.write('C2', todays_date, workbook.add_format({'bold': True, 'font_size': 12}))\n",
    "\n",
    "\n",
    "            current_row = 4  # Start at row 4 after the logo and date\n",
    "            \n",
    "\n",
    "            \n",
    "            for title, df in dfs:\n",
    "                worksheet.write(current_row - 1, 0, title, workbook.add_format({'bold': True, 'font_color': 'black'}))\n",
    "                # Call a modified version of the format function that doesn't insert the logo again\n",
    "                format_sheet_without_alternating_colors(df, sheet_name, start_row=current_row, insert_logo=False)\n",
    "                current_row += len(df) + 3  # Add space between tables\n",
    "\n",
    "        # Apply formatting for DataFrames with alternating colors\n",
    "        for sheet_name, df in (dfs_with_format or {}).items():\n",
    "            format_sheet_with_alternating_colors(df, sheet_name)\n",
    "\n",
    "        # Apply formatting for DataFrames without alternating colors\n",
    "        for sheet_name, df in (dfs_without_format or {}).items():\n",
    "            format_sheet_without_alternating_colors(df, sheet_name)\n",
    "\n",
    "        # Apply formatting for multiple DataFrames on one sheet\n",
    "        for sheet_name, dfs in (dfs_multiple_on_sheet or {}).items():\n",
    "            format_multiple_dfs_on_sheet(dfs, sheet_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5f43e045-b2ef-4c80-9f3e-77340e710038",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Load the logo image\n",
    "logo_path = 'logo_vector.png'\n",
    "logo = Image.open(logo_path)\n",
    "\n",
    "# Resize the image\n",
    "resized_logo = logo.resize((240, 60))\n",
    "\n",
    "# Save the resized image to a new file\n",
    "resized_logo_path = 'resized_logo_vector.png'\n",
    "resized_logo.save(resized_logo_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8d5aeb48-76e2-450c-9f47-4329208b4364",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cartera_detalle.rename(columns={\n",
    "        'NUM_CUENTA': 'Número Cuenta',\n",
    "        'NOMBRE_CLI': 'Descripción',\n",
    "        'NOMBRE_ASESOR': 'Asesor',\n",
    "        'NEMOTECNICO': 'Nemotécnico',\n",
    "        'COD_SUB_CLASE_INSTRUMENTO': 'Código instrumento',\n",
    "        'VALOR_MERCADO_CLP': 'Valor Mercado CLP',\n",
    "        'LIBRE': 'Libre',\n",
    "        'GARANTIA': 'Garantía',\n",
    "        'PRECIO_TASA_COMPRA':'Precio tasa compra',\n",
    "        'PRECIO_TASA_MERCADO':'Precio tasa mercado',\n",
    "        'COMPRAS_PLAZO': 'Compras Plazo',\n",
    "        'VENTAS_PLAZO': 'Ventas Plazo',\n",
    "        'PRESTAMOS_ACC': 'Préstamos',\n",
    "        'LIBRE_CLP': 'Libre CLP',\n",
    "        'GARANTIA_CLP': 'Garantía CLP',\n",
    "        'SIM_COMPRA_CLP': 'Sim compra clp',\n",
    "        'SIM_VENTA_CLP': 'Sim venta clp'},\n",
    "inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "df_resumen.rename(columns={'NOMBRE CLIENTE': 'Descripción',\n",
    "                           'NIVEL': 'Directo/Indirecto', \n",
    "                           'PEP RELACIONADO': 'Pep relacionado', \n",
    "                           'POSICION PEP RELACIONADO': 'Posición pep relacionado', \n",
    "                           'RUT PEP RELACIONADO': 'Rut pep relacionado', \n",
    "                           'RELACION': 'Relación',\n",
    "                           'ACC': 'Acciones', \n",
    "                           'ACC_INT': 'Acciones int', \n",
    "                           'CFI': 'CFI', \n",
    "                           'ETF': 'ETF', \n",
    "                           'FMF': 'FMF', \n",
    "                           'TOTAL CUSTODIA CLP': 'Total custodia', \n",
    "                           \n",
    "                           'CAJA DOLAR': 'Caja dolar', \n",
    "                           'CAJA PESO': 'Caja peso',\n",
    "                           'TOTAL CAJA CLP': 'Caja', \n",
    "                           \n",
    "                           'ABONO_CAJA_DOLAR': 'Abono caja dolar', \n",
    "                           'ABONO_CAJA_PESO': 'Abono caja peso', \n",
    "                           'CARGO_CAJA_DOLAR': 'Cargo caja dolar', \n",
    "                           'CARGO_CAJA_PESO': 'Cargo caja peso', \n",
    "                           'ASESORES': 'Asesores', \n",
    "\n",
    "                           'PROFESION': 'Profesión', \n",
    "                           'EMPLEADOR': 'Empleador', \n",
    "                           'CARGO': 'Cargo', \n",
    "                           'FECHA_OPERATIVA': 'Fecha inicio', \n",
    "                           'PERFIL_RIESGO': 'Perfil inversionista', \n",
    "                           'FECHA_NACIMIENTO': 'Fecha nacimiento', \n",
    "                           'PAIS': 'País', \n",
    "                           'PRODUCTOS_OPERADOS': 'Productos operados', \n",
    "                           'CANTIDAD_OPERACIONES': 'Número de operaciones', \n",
    "                           'FECHA_ULTIMA_OPERACION': 'Última operación', \n",
    "                           'ULTIMO_INSTRUMENTO_OPERADO': 'Último instrumento operado'}, \n",
    "                  \n",
    "                  inplace=True)\n",
    "\n",
    "\n",
    "df_saldo_caja.rename(columns={\n",
    "            'NUM_CUENTA': 'Número cuenta',\n",
    "            'NOMBRE_CLI': 'Descripción',\n",
    "            'NOMBRE_ASESOR': 'Asesor',\n",
    "            'TIPO_CAJA': 'Tipo caja',\n",
    "            'MONTO_MON_CAJA': 'Monto caja',\n",
    "            'MONTO_EN_PESOS': 'Monto en pesos',\n",
    "            'TRANSITO': 'Tránsito'},\n",
    "\n",
    "            inplace=True)\n",
    "\n",
    "\n",
    "df_APORET_detalle.rename(columns={\n",
    "            'CARGO_ABONO': 'Cargo/Abono',\n",
    "            'NUM_CUENTA': 'Número cuenta',\n",
    "            'NOMBRE_CLI': 'Descripción',\n",
    "            'COD_MOV': 'Código movimiento',\n",
    "            'DSC_MOV_CAJA': 'Descripción movimiento caja',\n",
    "            'FECHA_MOVIMIENTO': 'Fecha movimiento',\n",
    "            'MONTO': 'Monto',\n",
    "            'NOMBRE_ASESOR': 'Asesor',\n",
    "            'TIPO_CAJA': 'Tipo caja',\n",
    "            'COD_MONEDA': 'Código moneda',\n",
    "            'T_C': 'Tipo Cambio',\n",
    "            'MONTO_CLP': 'Monto en CLP'},\n",
    "inplace=True)\n",
    "\n",
    "\n",
    "df_ultima_operacion.rename(columns={\n",
    "            'NUM_CUENTA': 'Número cuenta',\n",
    "            'NOMBRE_CLIENTE': 'Descripción',\n",
    "            'NOMBRE_ASESOR': 'Asesor',\n",
    "            'FECHA_OPERACION': 'Fecha operación',\n",
    "            'COD_TIPO_OPERACION': 'Código tipo operación',\n",
    "            'DSC_OPERACION_CONCEPTO': 'Descripción operación',\n",
    "            'COD_MONEDA_OP': 'Código moneda',\n",
    "            'NEMOTECNICO': 'Nemotécnico',\n",
    "            'DSC_INSTRUMENTO': 'Descripción instrumento',\n",
    "            'COD_SUB_CLASE_INSTRUMENTO': 'Código sub clase instrumento',\n",
    "            'CANTIDAD': 'Cantidad',\n",
    "            'MONTO': 'Monto',\n",
    "            'MONTO_OPERACION': 'Monto operación'},\n",
    "inplace=True)\n",
    "\n",
    "\n",
    "df_indicador_numero.rename(columns={\n",
    "            'CUSTODIA': 'Custodia',\n",
    "            'MONTO': 'Monto'},\n",
    "inplace=True)\n",
    "\n",
    "df_indicador_numero2.rename(columns={\n",
    "            'CUSTODIA': 'Custodia',\n",
    "            'MONTO': 'Monto'},\n",
    "inplace=True)\n",
    "\n",
    "top10_custodia.rename(columns={\n",
    "            'IDENTIFICADOR': 'Rut',\n",
    "            'NOMBRE CLIENTE': 'Descripción',\n",
    "            'TOTAL CUSTODIA CLP': 'Total Custodia CLP'},\n",
    "inplace=True)\n",
    "\n",
    "top10_caja.rename(columns={\n",
    "            'IDENTIFICADOR': 'Rut',\n",
    "            'NOMBRE CLIENTE': 'Descripción',\n",
    "            'TOTAL CUSTODIA CLP': 'Total Custodia CLP'},\n",
    "inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "################################\n",
    "df_info_personal_test.rename(columns={\n",
    "'NUM_CUENTA': 'Número cuenta',\n",
    "'NOMBRE_CLIENTE': 'Descripción',\n",
    "'NOMBRE_ASESOR': 'Asesor',\n",
    "'FECHA_OPERACION': 'Fecha operación',\n",
    "'COD_TIPO_OPERACION': 'Código tipo operación',\n",
    "'DSC_OPERACION_CONCEPTO': 'Descripción operación concepto',\n",
    "'COD_MONEDA_OP': 'Código moneda operación',\n",
    "'NEMOTECNICO': 'Nematécnico',\n",
    "'DSC_INSTRUMENTO': 'Descripción instrumento',\n",
    "'COD_SUB_CLASE_INSTRUMENTO': 'Código sub clase instrumento',\n",
    "'CANTIDAD': 'Cantidad',\n",
    "'MONTO': 'Monto',\n",
    "'MONTO_OPERACION': 'Monto operación'},\n",
    "\n",
    "inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9c94412d-9f22-4395-ba3e-69cc37ad50b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "format_and_save_excel_with_alternating_colors(\n",
    "    'Informe PEP 18-10.xlsx',\n",
    "    'resized_logo_vector.png',\n",
    "    dfs_with_format={'Detalle Cartera': df_cartera_detalle,\n",
    "                     'Detalle Caja': df_saldo_caja, \n",
    "                     'Detalle Aportes Retiros': df_APORET_detalle,\n",
    "                     'Detalle Operaciones': df_ultima_operacion\n",
    "                    \n",
    "                    },\n",
    "    dfs_without_format={\n",
    "                       'Detalle Ultima Operacion': df_info_personal_test,\n",
    "                       'Resumen': df_resumen\n",
    "                       },\n",
    "    dfs_multiple_on_sheet={\n",
    "        'Indicadores': [\n",
    "            ('Custodia PEP respecto total clientes', df_indicador_numero),\n",
    "            ('Custodia Top 10 respecto total clientes PEP', df_indicador_numero2),\n",
    "            ('Top 10 Custodia', top10_custodia),\n",
    "            ('Top 10 Caja', top10_caja)\n",
    "        ] + [(f'Top 10 {k}', df) for k, df in top10_products.items()]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2d4ba0-725d-4a00-8129-72625c15cd54",
   "metadata": {},
   "source": [
    "#### FORMAT EXCEL OTHER VERSIONS"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4472d025-76c5-4618-a5a3-3dcedd797eff",
   "metadata": {},
   "source": [
    "def format_and_save_excel_with_alternating_colors(filename, dfs_with_format=None, dfs_without_format=None, dfs_multiple_on_sheet=None):\n",
    "    if dfs_with_format is None:\n",
    "        dfs_with_format = {}\n",
    "    if dfs_without_format is None:\n",
    "        dfs_without_format = {}\n",
    "    if dfs_multiple_on_sheet is None:\n",
    "        dfs_multiple_on_sheet = {}\n",
    "\n",
    "    with pd.ExcelWriter(filename, engine='xlsxwriter') as writer:\n",
    "        # FORMATEO COLORES ALTERNOS\n",
    "        def format_sheet_with_alternating_colors(df, sheet_name):\n",
    "            df.to_excel(writer, sheet_name=sheet_name, index=False, startrow=3, header=False)\n",
    "\n",
    "            workbook = writer.book\n",
    "            worksheet = writer.sheets[sheet_name]\n",
    "\n",
    "            # FORMATO HEADER\n",
    "            header_format = workbook.add_format({\n",
    "                'bold': True,\n",
    "                'text_wrap': True,\n",
    "                'valign': 'top',\n",
    "                'fg_color': '#022596',\n",
    "                'font_color': 'white',\n",
    "                'border': 1\n",
    "            })\n",
    "\n",
    "            worksheet.set_default_row(15)\n",
    "            for col_idx in range(len(df.columns)):\n",
    "                worksheet.set_column(col_idx, col_idx, 20)\n",
    "\n",
    "            worksheet.add_table(1, 0, len(df) + 1, len(df.columns) - 1, {\n",
    "                'columns': [{'header': col} for col in df.columns],\n",
    "                'style': 'none'\n",
    "            })\n",
    "\n",
    "            # FORMATO \n",
    "            for col_num, value in enumerate(df.columns.values):\n",
    "                worksheet.write(1, col_num, value, header_format)\n",
    "\n",
    "            format1 = workbook.add_format({'bg_color': '#FFFFFF', 'align': 'left'})\n",
    "            format2 = workbook.add_format({'bg_color': '#E0FFFF', 'align': 'left'})\n",
    "            date_format1 = workbook.add_format({'bg_color': '#FFFFFF', 'align': 'left', 'num_format': 'yyyy-mm-dd'})\n",
    "            date_format2 = workbook.add_format({'bg_color': '#E0FFFF', 'align': 'left', 'num_format': 'yyyy-mm-dd'})\n",
    "\n",
    "            previous_identifier = None\n",
    "            format_to_use = format1\n",
    "            date_format_to_use = date_format1\n",
    "\n",
    "            for row_num, identifier in enumerate(df['IDENTIFICADOR'], start=2):\n",
    "                if identifier != previous_identifier:\n",
    "                    format_to_use = format2 if format_to_use == format1 else format1\n",
    "                    date_format_to_use = date_format2 if date_format_to_use == date_format1 else date_format1\n",
    "                    previous_identifier = identifier\n",
    "\n",
    "                for col_num in range(len(df.columns)):\n",
    "                    value = df.iloc[row_num - 2, col_num]\n",
    "\n",
    "                    if pd.isna(value) or (isinstance(value, float) and (value == float('inf') or value == -float('inf'))):\n",
    "                        value = ''  # Reemplaza NaN o Infinity con cadena vacia\n",
    "                    elif isinstance(value, (list, np.ndarray)):\n",
    "                        value = ', '.join(map(str, value))  # Convierte listas o arrays en una cadena\n",
    "\n",
    "                    if df.columns[col_num].startswith('FECHA'):\n",
    "                        worksheet.write(row_num, col_num, value, date_format_to_use)\n",
    "                    else:\n",
    "                        worksheet.write(row_num, col_num, value, format_to_use)\n",
    "\n",
    "        # FORMATEO HOJA SIN COLORES ALTERNOS\n",
    "        def format_sheet_without_alternating_colors(df, sheet_name, start_row=3):\n",
    "            df.to_excel(writer, sheet_name=sheet_name, index=False, startrow=start_row, header=False)\n",
    "\n",
    "            workbook = writer.book\n",
    "            worksheet = writer.sheets[sheet_name]\n",
    "\n",
    "            header_format = workbook.add_format({\n",
    "                'bold': True,\n",
    "                'text_wrap': True,\n",
    "                'valign': 'top',\n",
    "                'fg_color': '#022596',\n",
    "                'font_color': 'white',\n",
    "                'border': 1\n",
    "            })\n",
    "\n",
    "            worksheet.set_default_row(15)\n",
    "            for col_idx in range(len(df.columns)):\n",
    "                worksheet.set_column(col_idx, col_idx, 20)\n",
    "\n",
    "            # RANGO TABLA SEGUN START_ROW\n",
    "            worksheet.add_table(start_row, 0, start_row + len(df), len(df.columns) - 1, {\n",
    "                'columns': [{'header': col} for col in df.columns],\n",
    "                'style': 'none'\n",
    "            })\n",
    "\n",
    "            # FORMATO\n",
    "            for col_num, value in enumerate(df.columns.values):\n",
    "                worksheet.write(start_row, col_num, value, header_format)\n",
    "\n",
    "            cell_format = workbook.add_format({'align': 'left', 'bg_color': '#FFFFFF'})\n",
    "            date_format = workbook.add_format({'num_format': 'yyyy-mm-dd', 'bg_color': '#FFFFFF'})\n",
    "\n",
    "            for row_num in range(start_row + 1, start_row + len(df) + 1):\n",
    "                for col_num in range(len(df.columns)):\n",
    "                    value = df.iloc[row_num - start_row - 1, col_num]\n",
    "\n",
    "                    # Verifica si el valor es un array o lista antes de hacer comparaciones\n",
    "                    if isinstance(value, (list, np.ndarray)):\n",
    "                        value = ', '.join(map(str, value))  # Convierte listas o arrays en una cadena\n",
    "                    elif pd.isna(value) or (isinstance(value, float) and (value == float('inf') or value == -float('inf'))):\n",
    "                        value = ''  # Reemplaza NaN o Infinity con una cadena vacía\n",
    "\n",
    "                    if df.columns[col_num].startswith('FECHA'):\n",
    "                        worksheet.write(row_num, col_num, value, date_format)\n",
    "                    else:\n",
    "                        worksheet.write(row_num, col_num, value, cell_format)\n",
    "\n",
    "        # VARIOS DF EN UNA SHEET\n",
    "        def format_multiple_dfs_on_sheet(dfs, sheet_name):\n",
    "            workbook = writer.book\n",
    "            worksheet = workbook.add_worksheet(sheet_name)\n",
    "            writer.sheets[sheet_name] = worksheet\n",
    "\n",
    "            current_row = 0  # PRIMERA FILA\n",
    "\n",
    "            for title, df in dfs:\n",
    "                # TITULO DF\n",
    "                worksheet.write(current_row, 3, title, workbook.add_format({'bold': True, 'font_color': 'black'}))\n",
    "                current_row += 1  # Avanzamos una fila para los datos\n",
    "                format_sheet_without_alternating_colors(df, sheet_name, start_row=current_row)\n",
    "                # 2 FILAS DE SEPARACION\n",
    "                current_row += len(df) + 3  \n",
    "\n",
    "        # FORMATEO DF COLORES ALTERNOS\n",
    "        for sheet_name, df in (dfs_with_format or {}).items():\n",
    "            format_sheet_with_alternating_colors(df, sheet_name)\n",
    "\n",
    "        # FORMATEO DF SIN COLORES ALTERNOS\n",
    "        for sheet_name, df in (dfs_without_format or {}).items():\n",
    "            format_sheet_without_alternating_colors(df, sheet_name)\n",
    "\n",
    "        # FORMATEAR MULTIPLES INDICADORES EN UN DF\n",
    "        for sheet_name, dfs in (dfs_multiple_on_sheet or {}).items():\n",
    "             format_multiple_dfs_on_sheet(dfs, sheet_name)\n",
    "\n",
    "\n",
    "## i want all the sheets yo start at row number 4 in generated excel\n",
    "## furthermore i wanna ad logo_vector.png at the start (1,1) in every sheet generated, and at row 1 column D isnert date todays_date = date.today() "
   ]
  },
  {
   "cell_type": "raw",
   "id": "cdb0f5f0-22d4-4d6e-bb24-fdd6cef35511",
   "metadata": {},
   "source": [
    "from datetime import date\n",
    "import pandas as pd\n",
    "\n",
    "def format_and_save_excel_with_alternating_colors(filename, logo_path, dfs_with_format=None, dfs_without_format=None, dfs_multiple_on_sheet=None):\n",
    "    if dfs_with_format is None:\n",
    "        dfs_with_format = {}\n",
    "    if dfs_without_format is None:\n",
    "        dfs_without_format = {}\n",
    "    if dfs_multiple_on_sheet is None:\n",
    "        dfs_multiple_on_sheet = {}\n",
    "\n",
    "    todays_date = date.today().strftime('%Y-%m-%d')\n",
    "\n",
    "    with pd.ExcelWriter(filename, engine='xlsxwriter') as writer:\n",
    "        # FORMATEO COLORES ALTERNOS\n",
    "        def format_sheet_with_alternating_colors(df, sheet_name):\n",
    "            df.to_excel(writer, sheet_name=sheet_name, index=False, startrow=4, header=False)  # Start from row 4\n",
    "\n",
    "            workbook = writer.book\n",
    "            worksheet = writer.sheets[sheet_name]\n",
    "\n",
    "            # Insert the logo at B1 (row 1, column 2)\n",
    "            worksheet.insert_image('A1', logo_path)\n",
    "\n",
    "            # Insert today's date in D1\n",
    "            worksheet.write('C1', todays_date, workbook.add_format({'bold': True, 'font_size': 12}))\n",
    "\n",
    "            # FORMATO HEADER\n",
    "            header_format = workbook.add_format({\n",
    "                'bold': True,\n",
    "                'text_wrap': True,\n",
    "                'valign': 'top',\n",
    "                'fg_color': '#022596',\n",
    "                'font_color': 'white',\n",
    "                'border': 1\n",
    "            })\n",
    "\n",
    "            worksheet.set_default_row(15)\n",
    "            for col_idx in range(len(df.columns)):\n",
    "                worksheet.set_column(col_idx, col_idx, 20)\n",
    "\n",
    "            worksheet.add_table(3, 0, len(df) + 3, len(df.columns) - 1, {  # Adjust to row 4 (3-based index)\n",
    "                'columns': [{'header': col} for col in df.columns],\n",
    "                'style': 'none'\n",
    "            })\n",
    "\n",
    "            # Write the headers manually\n",
    "            for col_num, value in enumerate(df.columns.values):\n",
    "                worksheet.write(3, col_num, value, header_format)  # Header row at row 4 (3-based index)\n",
    "\n",
    "            # Alternate row colors\n",
    "            format1 = workbook.add_format({'bg_color': '#FFFFFF', 'align': 'left'})\n",
    "            format2 = workbook.add_format({'bg_color': '#E0FFFF', 'align': 'left'})\n",
    "            date_format1 = workbook.add_format({'bg_color': '#FFFFFF', 'align': 'left', 'num_format': 'yyyy-mm-dd'})\n",
    "            date_format2 = workbook.add_format({'bg_color': '#E0FFFF', 'align': 'left', 'num_format': 'yyyy-mm-dd'})\n",
    "\n",
    "            previous_identifier = None\n",
    "            format_to_use = format1\n",
    "            date_format_to_use = date_format1\n",
    "\n",
    "            for row_num, identifier in enumerate(df['IDENTIFICADOR'], start=4):  # Start at row 4\n",
    "                if identifier != previous_identifier:\n",
    "                    format_to_use = format2 if format_to_use == format1 else format1\n",
    "                    date_format_to_use = date_format2 if date_format_to_use == date_format1 else date_format1\n",
    "                    previous_identifier = identifier\n",
    "\n",
    "                for col_num in range(len(df.columns)):\n",
    "                    value = df.iloc[row_num - 4, col_num]  # Adjust for the new row index\n",
    "\n",
    "                    if pd.isna(value) or (isinstance(value, float) and (value == float('inf') or value == -float('inf'))):\n",
    "                        value = ''  # Replace NaN or Infinity with an empty string\n",
    "                    elif isinstance(value, (list, np.ndarray)):\n",
    "                        value = ', '.join(map(str, value))  # Convert lists or arrays to a string\n",
    "\n",
    "                    if df.columns[col_num].startswith('FECHA'):\n",
    "                        worksheet.write(row_num, col_num, value, date_format_to_use)\n",
    "                    else:\n",
    "                        worksheet.write(row_num, col_num, value, format_to_use)\n",
    "\n",
    "        # FORMATEO HOJA SIN COLORES ALTERNOS\n",
    "        def format_sheet_without_alternating_colors(df, sheet_name, start_row=3):\n",
    "            df.to_excel(writer, sheet_name=sheet_name, index=False, startrow=start_row, header=False)\n",
    "\n",
    "            workbook = writer.book\n",
    "            worksheet = writer.sheets[sheet_name]\n",
    "\n",
    "            # Insert the logo at B1 (row 1, column 2)\n",
    "            worksheet.insert_image('A1', logo_path)\n",
    "\n",
    "            # Insert today's date in D1\n",
    "            worksheet.write('C1', todays_date, workbook.add_format({'bold': True, 'font_size': 12}))\n",
    "\n",
    "            header_format = workbook.add_format({\n",
    "                'bold': True,\n",
    "                'text_wrap': True,\n",
    "                'valign': 'top',\n",
    "                'fg_color': '#022596',\n",
    "                'font_color': 'white',\n",
    "                'border': 1\n",
    "            })\n",
    "\n",
    "            worksheet.set_default_row(15)\n",
    "            for col_idx in range(len(df.columns)):\n",
    "                worksheet.set_column(col_idx, col_idx, 20)\n",
    "\n",
    "            worksheet.add_table(start_row, 0, start_row + len(df), len(df.columns) - 1, {\n",
    "                'columns': [{'header': col} for col in df.columns],\n",
    "                'style': 'none'\n",
    "            })\n",
    "\n",
    "            # Write the headers manually\n",
    "            for col_num, value in enumerate(df.columns.values):\n",
    "                worksheet.write(start_row, col_num, value, header_format)\n",
    "\n",
    "            cell_format = workbook.add_format({'align': 'left', 'bg_color': '#FFFFFF'})\n",
    "            date_format = workbook.add_format({'num_format': 'yyyy-mm-dd', 'bg_color': '#FFFFFF'})\n",
    "\n",
    "            for row_num in range(start_row + 1, start_row + len(df) + 1):\n",
    "                for col_num in range(len(df.columns)):\n",
    "                    value = df.iloc[row_num - start_row - 1, col_num]\n",
    "\n",
    "                    if isinstance(value, (list, np.ndarray)):\n",
    "                        value = ', '.join(map(str, value))  # Convert lists or arrays to a string\n",
    "                    elif pd.isna(value) or (isinstance(value, float) and (value == float('inf') or value == -float('inf'))):\n",
    "                        value = ''  # Replace NaN or Infinity with an empty string\n",
    "\n",
    "                    if df.columns[col_num].startswith('FECHA'):\n",
    "                        worksheet.write(row_num, col_num, value, date_format)\n",
    "                    else:\n",
    "                        worksheet.write(row_num, col_num, value, cell_format)\n",
    "\n",
    "        # VARIOS DF EN UNA SHEET\n",
    "        def format_multiple_dfs_on_sheet(dfs, sheet_name):\n",
    "            workbook = writer.book\n",
    "            worksheet = workbook.add_worksheet(sheet_name)\n",
    "            writer.sheets[sheet_name] = worksheet\n",
    "\n",
    "            current_row = 3  # Start at row 4\n",
    "\n",
    "            for title, df in dfs:                ## \n",
    "                worksheet.write(current_row - 1, 0, title, workbook.add_format({'bold': True, 'font_color': 'black'}))\n",
    "                format_sheet_without_alternating_colors(df, sheet_name, start_row=current_row)\n",
    "                current_row += len(df) + 3  # Add space between tables\n",
    "\n",
    "        # Apply formatting for DataFrames with alternating colors\n",
    "        for sheet_name, df in (dfs_with_format or {}).items():\n",
    "            format_sheet_with_alternating_colors(df, sheet_name)\n",
    "\n",
    "        # Apply formatting for DataFrames without alternating colors\n",
    "        for sheet_name, df in (dfs_without_format or {}).items():\n",
    "            format_sheet_without_alternating_colors(df, sheet_name)\n",
    "\n",
    "        # Apply formatting for multiple DataFrames on one sheet\n",
    "        for sheet_name, dfs in (dfs_multiple_on_sheet or {}).items():\n",
    "            format_multiple_dfs_on_sheet(dfs, sheet_name)\n",
    "\n",
    "## WHY THERE IS 7 PNG IMAGES AT format_multiple_dfs_on_sheet IT ONLY SHOULD BE ONE PNG"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
